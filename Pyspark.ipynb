{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework #8\n",
    "### Name: Revan Minnam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the location of the data sets and create the text RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/public/bmort/spark/'\n",
    "storeRDD = sc.textFile(path + 'wegmans_store_master.txt')\n",
    "itemRDD = sc.textFile(path + 'wegmans_item_master.txt')\n",
    "customerRDD = sc.textFile(path + 'wegmans_customer_master.txt')\n",
    "postransRDD = sc.textFile(path + 'partial_transaction.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a pipe-delimited parsing function to split data based on the pipe character and repackage the returned results as a Row object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pyspark.sql import Row\n",
    "def parseStore(s):\n",
    "    l = s.split('|')\n",
    "    return Row(store_num = int(l[0]), \n",
    "               store_name = l[1],               \n",
    "               store_zone = l[2],\n",
    "               store_city = l[3], \n",
    "               store_state = l[4], \n",
    "               store_type = int(l[5]))\n",
    "def parseItem(s):\n",
    "    l = s.split('|')\n",
    "    return Row(item_number = int(l[0]), \n",
    "               dept_categ_class = l[1],               \n",
    "               item_des = l[2],\n",
    "               item_unt_qty = float(l[3]), \n",
    "               size_unit_desc = l[4], \n",
    "               brand_code = l[5], \n",
    "               dept_num = int(l[6]), \n",
    "               dept_name = l[7], \n",
    "               categ_num = int(l[8]), \n",
    "               categ_name = l[9], \n",
    "               class_num = int(l[10]),\n",
    "               class_name = l[11])\n",
    "def parseCustomer(s):\n",
    "    l = s.split('|')\n",
    "    return Row(hshld_acct = int(l[0]),\n",
    "               birth_yr_head_hh = l[1],\n",
    "               hh_income = l[2],\n",
    "               hh_size = l[3],\n",
    "               adult_count = l[4],\n",
    "               child_count = l[5],\n",
    "               birth_yr_oldest = l[6],\n",
    "               birth_yr_youngest = l[7],\n",
    "               bad_address = l[8],\n",
    "               privacy = l[9],\n",
    "               application_date = datetime.strptime(l[10],'%Y-%m-%d'),\n",
    "               wine_email_sent = int(l[11]),\n",
    "               wine_email_open = int(l[12]),\n",
    "               wine_email_click = int(l[13]))\n",
    "def parsePostrans(s):\n",
    "    l = s.split('|')\n",
    "    return Row(hshld_acct = int(l[0]),\n",
    "               acct_num = int(l[1]),\n",
    "               trans_num = int(l[2]),\n",
    "               trans_date = datetime.strptime(l[3],'%Y-%m-%d'),\n",
    "               store_num = int(l[4]),\n",
    "               item_number = int(l[5]),\n",
    "               dept_categ_class = l[6],\n",
    "               unit_count = int(l[7]),\n",
    "               net_sales = float(l[8]),\n",
    "               gross_sales = float(l[9]),\n",
    "               manuf_coupon = float(l[10]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the row-based RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storeRowRDD = storeRDD.map(parseStore)\n",
    "itemRowRDD = itemRDD.map(parseItem)\n",
    "customerRowRDD = customerRDD.map(parseCustomer)\n",
    "postransRowRDD = postransRDD.map(parsePostrans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate data frames from the RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "storeDF = sqlContext.createDataFrame(storeRowRDD)\n",
    "itemDF = sqlContext.createDataFrame(itemRowRDD)\n",
    "customerDF = sqlContext.createDataFrame(customerRowRDD)\n",
    "postransDF = sqlContext.createDataFrame(postransRowRDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create temporary views for the data frames for use in a SQL context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storeDF.createOrReplaceTempView('store')\n",
    "itemDF.createOrReplaceTempView('item')\n",
    "customerDF.createOrReplaceTempView('customer')\n",
    "postransDF.createOrReplaceTempView('postrans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "* In the lecture we determined the total sales for each store. Now determine the total sales for each region. Your final output should have 2 columns (store_zone and total_sales) and 5 rows, corresponding to the 5 regions. Hint: Begin by joining the point of sale trasaction data frame with the store data frame. (It may take a few minutes to run your code.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete code here to produce the output\n",
    "from pyspark.sql import functions as F\n",
    "postransDF.join(storeDF, 'store_num') \\\n",
    "    .groupBy('store_zone') \\\n",
    "    .agg(F.sum('gross_sales').alias('total_sales')) \\\n",
    "    .select('store_zone','total_sales') \\\n",
    "    .sort('total_sales', ascending=False) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "* Calculate the total number of transactions (in the postransDF) for each store. Display the results in descending order by the number of transactions for the top 5 stores. Your final output should have 2 columns (store_name and count). The number of rows should be equal to 5. (It may take a few minutes to run your code.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete code here to produce the output\n",
    "postransDF.groupBy('store_num') \\\n",
    "    .agg(F.count('trans_num').alias('count')) \\\n",
    "    .join(storeDF, 'store_num') \\\n",
    "    .select('store_name', 'count') \\\n",
    "    .sort('count', ascending=False) \\\n",
    "    .show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (intel+spark 3.0.1)",
   "language": "python",
   "name": "intel-python3-spark-3.0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
